# Camden AI Classifier Configuration
#
# Copy this file to `camden-classifier.toml` and customize as needed.
#
# Simply specify which models to use by name.
# All model definitions are built into the application.

# =============================================================================
# BASIC CONFIGURATION
# =============================================================================
#
# Just pick the models you want to use:

moderation_model = "gantman-nsfw"
tagging_model = "wd-vit-tagger-v3"

# =============================================================================
# AVAILABLE MODERATION MODELS
# =============================================================================
#
# gantman-nsfw       5-class NSFW detection (drawings, hentai, neutral, porn, sexy)
#                    File: nsfw-inception-v3.onnx (~89 MB)
#                    Input: 299x299, NHWC layout
#                    DEFAULT - Good balance of accuracy and speed
#
# adamcodd-vit-nsfw  ViT-based NSFW detector (nsfw/sfw), high accuracy
#                    File: adamcodd-vit-base-nsfw.onnx (~344 MB)
#                    Input: 384x384, NCHW layout
#                    Best accuracy for binary NSFW detection
#
# nsfwjs             Lightweight NSFW detector (GantMan 5-class)
#                    File: nsfwjs.onnx (~10 MB)
#                    Input: 224x224, NHWC layout
#                    Fastest option, good for batch processing
#
# onnx-community-nsfw  ViT-based binary NSFW (nsfw/sfw)
#                    File: onnx-community-nsfw.onnx (~343 MB)
#                    Input: 224x224, NCHW layout
#
# spiele-nsfw        4-tier severity detector (neutral, sensitive, mature, restricted)
#                    File: spiele-nsfw.onnx (~346 MB)
#                    Input: 448x448, NCHW layout
#                    Best for content rating systems
#
# taufiqdp-mobilenetv4  MobileNetV4-based NSFW (GantMan 5-class compatible)
#                    File: taufiqdp-mobilenetv4_conv_small...onnx (~10 MB)
#                    Input: 224x224, NCHW layout
#                    Fast mobile-optimized model

# =============================================================================
# AVAILABLE TAGGING MODELS
# =============================================================================
#
# ImageNet Models (1000 classes - objects, animals, scenes):
# ----------------------------------------------------------
# NOTE: ImageNet models classify into 1000 categories like "golden retriever",
# "sports car", "pizza". Good for object identification, not rich tagging.
#
# mobilenetv2        Fast ImageNet classification
#                    File: mobilenetv2-12.onnx (~14 MB)
#                    Input: 224x224, NCHW layout
#
# efficientnet-lite4 Higher accuracy ImageNet
#                    File: efficientnet-lite4-11.onnx (~52 MB)
#                    Input: 224x224, NCHW layout
#
# resnet50           Classic ResNet architecture
#                    File: resnet50-v2-7.onnx (~102 MB)
#                    Input: 224x224, NCHW layout
#
# vit-base-224       Vision Transformer (ViT) ImageNet
#                    File: vit-base-224.onnx (~346 MB)
#                    Input: 224x224, NCHW layout
#
# vit-base-224-q8    Vision Transformer quantized (faster, smaller)
#                    File: vit-base-224-q8.onnx (~88 MB)
#                    Input: 224x224, NCHW layout
#
# convnextv2-large   ConvNeXtV2 Large, high accuracy
#                    File: convnextv2-large-1k-224.onnx (~200 MB)
#                    Input: 224x224, NCHW layout
#
# Danbooru-style Taggers (10,000+ tags - RECOMMENDED for rich tagging):
# ---------------------------------------------------------------------
# NOTE: WD taggers provide detailed multi-label tagging with 10,861 tags
# covering characters, styles, compositions, colors, and more.
# Best for anime/artwork but also works for general images.
#
# wd-vit-tagger-v3       WD ViT Tagger V3 (RECOMMENDED)
#                        File: wd-vit-tagger-v3.onnx (~378 MB)
#                        Input: 448x448, NHWC layout
#
# wd-swinv2-tagger-v3    WD SwinV2 Tagger V3
#                        File: wd-swinv2-tagger-v3.onnx (~467 MB)
#                        Input: 448x448, NHWC layout
#
# wd-vit-large-tagger-v3 WD ViT Large Tagger V3 (highest accuracy)
#                        File: wd-vit-large-tagger-v3.onnx (~1.2 GB)
#                        Input: 448x448, NHWC layout
#
# wd-eva02-large-tagger-v3  WD EVA02 Large Tagger V3
#                        File: wd-eva02-large-tagger-v3.onnx (~1.2 GB)
#                        Input: 448x448, NHWC layout
#
# p1atdev-wd-swinv2-tagger-v3-hf  Quantized WD SwinV2 (faster)
#                        File: p1atdev-wd-swinv2-tagger-v3-hf.onnx (~105 MB)
#                        Input: 448x448, NHWC layout
#
# All WD taggers use: wd-tags.csv for labels

# =============================================================================
# OPTIONAL: Path Customization
# =============================================================================
#
# Uncomment to override default paths:
#
# models_dir = ".vendor/models"
# ort_library = ".vendor/onnxruntime/lib/onnxruntime.dll"

# =============================================================================
# ADVANCED: Custom Model Override
# =============================================================================
#
# You can override built-in model settings or add new models.
# This is only needed for advanced use cases.
#
# [models.my-custom-model]
# name = "My Custom Model"
# type = "moderation"  # or "tagging"
# path = "my-model.onnx"
#
# [models.my-custom-model.input]
# width = 224
# height = 224
# normalize = true
# layout = "NCHW"
#
# [models.my-custom-model.output]
# num_classes = 2
# labels = ["safe", "unsafe"]
